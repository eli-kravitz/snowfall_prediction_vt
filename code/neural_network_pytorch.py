import torchfrom sklearn.metrics import confusion_matriximport matplotlib.pyplot as pltimport pickleimport osimport seaborn as snsfrom sklearn.model_selection import train_test_splitfrom imblearn.under_sampling import RandomUnderSamplerimport numpy as np# Load data filepwd = os.getcwd()save_loc = os.path.join(pwd, 'nbc_data')file_name = 'nbc_cat_data.pkl'full_file = os.path.join(save_loc, file_name)with open(full_file, 'rb') as input_file:    data_cat = pickle.load(input_file)# Separate labels and featuresy_str = np.array(data_cat.loc[:, 'snowfall'], dtype=str).Ty_str = np.array([y_str]).Tenum = enumerate(np.unique(y_str))d = dict((i,j) for i, j in enum)int_labels = []for i in range(len(y_str)):    val = y_str[i][0]    idx = list(d.values()).index(val)    int_labels.append(idx) y = np.array(int_labels)X = data_cat.drop(['snowfall'], axis=1)X = (X - X.mean()) / X.std()X = np.array(X, dtype=float)# Separate test and train dataX_train, X_test, y_train, y_test = train_test_split(X, y,    test_size=0.3, random_state=42)# We would like a balanced dataset - make equal labels with undersamplingunder_sampler = RandomUnderSampler(sampling_strategy='majority')X_train, y_train = under_sampler.fit_resample(X_train, y_train)X_train = torch.tensor(X_train, dtype=torch.float)X_test = torch.tensor(X_test, dtype=torch.float)y_train = torch.tensor(y_train, dtype=torch.long)y_test = torch.tensor(y_test, dtype=torch.long)from torch import nn, optimimport torch.nn.functional as Fclass Classifier(nn.Module):    def __init__(self):        super().__init__()        self.fc1 = nn.Linear(13, 500)        self.fc2 = nn.Linear(500, 250)        self.fc3 = nn.Linear(250, 120)        self.fc4 = nn.Linear(120, 60)        self.fc5 = nn.Linear(60, 32)        self.fc6 = nn.Linear(32, 12)    def forward(self, x):        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = F.relu(self.fc3(x))        x = F.relu(self.fc4(x))        x = F.relu(self.fc5(x))        x = F.log_softmax(self.fc6(x))        return x    model = Classifier()criterion = nn.NLLLoss()optimizer = optim.Adam(model.parameters(), lr=0.001)    epochs = 2000running_loss = []for e in range(epochs):    log_ps = model(X_train)    loss = criterion(log_ps, y_train)    optimizer.zero_grad()    loss.backward()    optimizer.step()    running_loss.append(loss.item())    # Place to save figspwd = os.getcwd()save_loc = os.path.join(pwd, 'figs', 'NN')if not os.path.isdir(save_loc):    os.mkdir(save_loc)    # Plot confuision matrixpred_mat = torch.exp(model(X_test))   names = np.unique(y_str)pred = []for row in pred_mat:    max_idx = int(torch.argmax(row))    pred.append(max_idx)truth = y_testconfuse = confusion_matrix(truth, pred)confuse = confuse.astype('float')for (i, r) in enumerate(confuse):    confuse[i] = r / sum(r)plt.figure(figsize=(20, 20))fx = sns.heatmap(confuse, annot=True, fmt='.2f', cmap='GnBu')fx.set_title('Confusion Matrix \n');fx.set_xlabel('\n Predicted Values\n')fx.set_ylabel('Actual Values\n');fx.xaxis.set_ticklabels(names)fx.yaxis.set_ticklabels(names)file_name = 'deep_NN_confusion.png'plt.savefig(os.path.join(save_loc, file_name), dpi=300, bbox_inches='tight')# Plot loss by epochplt.figure()plt.plot(range(len(running_loss)), running_loss)plt.xlabel('Epoch')plt.ylabel('Loss')plt.title('Loss by Epoch')plt.grid()file_name = 'deep_NN_loss.png'plt.savefig(os.path.join(save_loc, file_name), dpi=300, bbox_inches='tight')    # Make location to save modelpwd = os.getcwd()save_loc = os.path.join(pwd, 'NN_data')if not os.path.isdir(save_loc):    os.mkdir(save_loc)    file_name = 'deep_NN_model.pkl'full_file = os.path.join(save_loc, file_name)    # Save datawith open(full_file, 'wb') as handle:    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)    